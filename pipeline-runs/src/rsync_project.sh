#!/bin/bash

##
## Rsynces software required to run a pipeline to
#  between local and remote servers
# 
#Usage:
# ./rsync_project.sh path2/pipeline.cfg ec2-user@ec2-host bowtie2-2.3.4.3-linux-x86_64,RSEM-v1.3.0,STAR-2.6.1b
#
source /etc/profile.d/biocore.sh

cd `dirname $0`
script_name=`basename $0`
## Check expected structure
working_dir=`pwd`
parent_dir=`dirname $working_dir`

PIPELINE_CONFIG_FILE=$1
remote_server=$2
INDEXERS=$3

CURRENT_USER=`id -un`
rsync_script=rsync_software.sh

prog_usage(){
   echo "********************************************************"
   echo""
   echo "Usage: ./$script_name path2/pipeline.cfg remote_server [indexers]"
   echo""
   echo "Where:"
   echo "path2_pipeline.cfg: Required - is the full path to your pipeline project config file."
   echo " The pipeline config file is generated by running the program gen_config.sh"
   echo "remote_server: Required - aws cloud login - ec2-user@host "
   echo "indexers: Optional - commas separated list of indexers used as found under /data/transformed "
   echo ""
   echo "Example : ./$script_name /data/scratch/rna-seq/JarodRollins/JR18-08/results/cfgs/pipeline.cfg\
          ec2-user@ec2-18-204-34-149.compute-1.amazonaws.com bowtie2-2.3.4.3-linux-x86_64,RSEM-v1.3.0,STAR-2.6.1b"
   echo ""
   echo "The program triggers a data transfer between the local and remote servers"
   echo " for a given project. Only data associated to a project is transfered. "
   echo ""
   echo "Data to transfer to the cloud:"
   echo "1) /data/scratch/rna-seq/team-name/project_dir"
   echo "2) /data/projects/Biocore/biocore-pipelines/pipeline-runs-meta/project_dir"
   echo "3) /data/projects/Biocore/biocore-pipelines/rna-seq/project_dir"
   echo "4) /data/transformed/indexer/dataset-version/organism*"
   echo ""
}
if [ -z "${PIPELINE_CONFIG_FILE}" ]
then
   echo" Must specify the path2/pipeline.cfg"
   prog_usage
   exit 1
fi
if [ -z $REMOTE_SERVER ]
then
   echo" Must specify the remote server"
   prog_usage
   exit 1
fi
source ${PIPELINE_CONFIG_FILE}

log=$script_name.log
rm -f $log
touch $log

echo "********************************************************" | tee -a $log
echo "Rsyncing data for project:$PROJECT_NAME  " | tee -a $log
echo "********************************************************"| tee -a $log  

date
PROJECT_META_BASE=$PIPELINE_META_BASE/$PROJECT_NAME
PROJECT_JSON_BASE=$PATH2_JSON_FILE
#CWL_SCRIPT
cd $working_dir
if [ ! -f ${rsync_script} ]
then
   echo "ERROR: The main rsync file ${rsync_script} - not found  on `uname -n ` " | tee -a $log
   exit 1
fi
## Check that the cwl script exist
if [ ! -f $CWL_SCRIPT ]
then
  echo "ERROR: The main cwl file ${CWL_SCRIPT} - not found  on `uname -n ` " | tee -a $log
  exit 1
fi
## Check that a pcf file was generated for each sample
## and for each pcf, check that the specified json file 
#  and the cwl script exist 
issue_found=false
for sample_id in ${SAMPLES}
do
   #The pcf file name format: sample_id.organism.pcf
   if [ -f  $PROJECT_META_BASE/$sample_id.$ORGANISM.pcf ]
   then
        source $PROJECT_META_BASE/$sample_id.$ORGANISM.pcf
        if [ ! -f $CWL_SCRIPT ]
        then 
            issue_found=true
            echo "ERROR: Invalid cwl file ${CWL_SCRIPT} in $PROJECT_META_BASE/$sample_id.$ORGANISM.pcf " | tee -a $log
        fi
        if [ ! -f $JSON_FILE ]
        then
            issue_found=true  
            echo "ERROR: Invalid json file ${JSON_FILE} in $PROJECT_META_BASE/$sample_id.$ORGANISM.pcf " | tee -a $log
        fi
   else
     echo "ERROR: The pcf file $PROJECT_META_BASE/$sample_id.$ORGANISM.pcf - not found  on `uname -n ` " | tee -a $log
     issue_found=true
   fi 
done

#Procced with data transfer if there is no issue
if [  "$issue_found" = true ]
then
 echo "$issue_found: Missing expected files. Check the log for details."| tee -a $log
 exit 1
fi
#Path to the reference data
database_version=$REF_DATABASE-$REF_DATABASE_VERSION
dataset_base=$SCRATCH_BASE/$database_version
#Path to the reads and design file
project_reads_base=$SCRATCH_BASE/$PROJECT_TEAM_NAME
cwl_base=`dirname $CWL_SCRIPT`
echo "***************************************************************"| tee -a $log
echo "Data Migration Started:"`date`| tee -a $log
echo "Data Migration Script:${rsync_script} "| tee -a $log
echo "Local Server:"`uname -n`| tee -a $log
echo "Remote Server:$remote_server"| tee -a $log

echo "***************************************************************"
# rsync meta files
echo `date`" - Migrating meta files: $PIPELINE_META_BASE/$PROJECT_NAME to $remote_server:$PIPELINE_META_BASE"| tee -a $log
./${rsync_script} $PIPELINE_META_BASE/$PROJECT_NAME $remote_server $PIPELINE_META_BASE 2>&1 | tee -a $log
## rsync json files
echo `date`" - Migrating json files:$PATH2_JSON_FILES to $remote_server:$PIPELINE_PROJECTS_BASE"| tee -a $log
./${rsync_script} $PATH2_JSON_FILES $remote_server $PIPELINE_PROJECTS_BASE
# rsync cwl script
echo  `date`" - Migrating cwl script: $CWL_SCRIPT to $remote_server:$cwl_base"| tee -a $log
./${rsync_script} $CWL_SCRIPT $remote_server $cwl_base
# rsync scratch reads
echo `date`" - Migrating sequence reads: $project_reads_base/$PROJECT_NAME to $remote_server:$project_reads_base/"| tee -a $log
./${rsync_script}  $project_reads_base/$PROJECT_NAME $remote_server $project_reads_base/
# rsync scratch datasets
echo `date`" - Migrating reference dataset:$dataset_base/$ORGANISM* to $remote_server:$dataset_base/"| tee -a $log
./${rsync_script} $dataset_base/$ORGANISM* $remote_server $dataset_base/

# rsync data/transform  for each index tool used in the pipeline
if [ ! -z $INDEXERS ]
then
  IFS=',' read  -a indexers_list <<< "$INDEXERS"
  for indexer in "${indexers_list[@]}"
  do
    echo `date`" - Migrating $indexer reference indexes: $INDEX_BASE/$indexer/$database_version/$ORGANISM* to $remote_server:$INDEX_BASE/$indexer/$database_version/"| tee -a $log
    ./${rsync_script} $INDEX_BASE/$indexer/$database_version/$ORGANISM* $remote_server $INDEX_BASE/$indexer/$database_version/
  done
fi
echo "Data Migration Started:"`date`| tee -a $log
date
exit 0

